\documentclass[10pt]{article}
%	options include 12pt or 11pt or 10pt
%	classes include article, report, book, letter, thesis
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{authblk}
\usepackage{hyperref}
\usepackage{fullpage}
\usepackage{times}
\usepackage{caption}
\usepackage{wrapfig}
\usepackage{capt-of}
\newcommand{\tion}[1]{Task~\ref{#1}}
\newcommand{\fig}[1]{Fig.~\ref{#1}}

\title{\textbf{Simulation Project --- 1}}
\author{Rahul Krishna}
\affil{North Carolina State University\\Email: \href{mailto:rkrish11@ncsu.edu}{rkrish11@ncsu.edu}\thanks{Source code: \url{https://github.com/rahlk/CSC579__Computer_Performance_Modeling}}}
\date{}

\begin{document}
\maketitle
\section{Task 1}
\label{task1}
\textit{Let us define the customer loss rate
 (CLR) as: CLR = $\frac{X}{N}$. Let the queue capacity K = 20. Plot the CLR against the value of
 $\rho$, for $\rho$ = 0.05 to $\rho$ = 0.95, in increments of 0.10. Submit two graphs: one for C = 1000 and one for C = 100000. Do you see any difference in the two plots? If so, can you explain the difference? If not, why do you think there is no difference? Explain your answer. Did you expect these results before running the experiment?\\}
 
 \input{task1.tex}
 
 The plot of CLR against values of $rho$ for $\rho=0.05, 0.15,\ldots,0.95$ are shown in Fig. \ref{fig1}. 
 
 \begin{enumerate}
 
 \item This Fig indicates that the loss rate is 0 throughout the experiments for low values of $\rho$.This is because of the customer arrival time is exponentially distributed with rate $\lambda$ but the service time has a constant rate of $\mu=1$. This means that the customers are processed faster than they arrive. With a sufficiently large queue size (like K=20). There will be no dropped customers and thus CLR is 0.
 
 To verify if this is indeed the case, consider Fig. \ref{fig2}. Here K=5, and we see that with smaller queue, there are dropped customers are the arrival rate $\lambda$ approaches $\rho$.
 
 \item With K=20 (Fig. \ref{fig1}) we see no differences between the plots. This is because, once more, the queue size is large enough that even with $C=10^5$ served customers there are no losses. 
 
 Again, with K=5 (Fig. \ref{fig2}) we notice that there is a generally increasing trend $C=10^5$. The curves are much more smoother that with $C=1000$. This is because the $C=1000$ is too low to measure the loss rate.
 
 \item The results of Fig. \ref{fig1} were to be expected prior to simulation. Because, as mentioned previously, we were aware the K=20 was too big a queue size to loose any arriving customer. That's the reason K=5 was used to verify this.
 
 \end{enumerate}

\section{Task 2}
\label{task2}

\input{task2.tex}

\textit{Now let us fix $\rho = 0.85$. Plot the CLR against the value of the queue capacity K, as K increases from 10 to 100 in increments of 10. Explain the behavior of the plots as K increases, and especially, the rate of change in the CLR as a function of K . Is this expected? Also,explain any differences in the two graphs due to the length of each simulation run.} \\
The plots are shown in Fig. \ref{fig3}. The findings follow from that of \tion{task1}: 
\begin{enumerate}
 \item We can notice that there is a non-zero drop rate at the beginning with $K=10$. After that the drop rate is zero.
 \item The drop rate at $K=10$ with $C=1000$ is slightly larger than at $C=10^5$ because of the number of trial at $C=10^5$ is considerably larger that $C=1000$ (two orders of magnitude).
\end{enumerate}

\section{Task 3}
\label{task3}
\input{task3.tex}

The plot of theoretical customer loss rate (CLT) versus simulated CLR are shown in Figs.~~\ref{fig4},~~\ref{fig5},and~\ref{fig6}. We note that: 
\begin{enumerate}
\item The queue size of $K=20$ is too large and the simulated CLR is zero $\forall$ $\rho\in\{0.05,\ldots,0.95\}$. Therefore, Figs. \ref{fig5} and \ref{fig6} are shown to depict the CLR that is obtained via simulation has the same trend as that of CLR obtained theoretically.

\item The overall behavior shows that as $\rho$ increases the customer loss rate also increases. This can be explained by reflecting on the nature of the exponential distribution that is used to generate the service/interarrival times. As $\rho$, therefore $\lambda$ (because $\rho=\lambda$) approaches 1, the interarrival times are too close to the service time (which was set to $\mu=1$). Therefore, the likelihood of dropping service increases.
\end{enumerate}

\input{task4.tex}

\section{Task 4}
\label{task4}

The plot of customer wait times versus $\rho$ is shown in Fig.~\ref{fig7}. There is a negligible increase in wait times as $\rho$ increases. We can consider that this is almost a constant. This is to be expected. The queue size is constant at K=100. The wait times would depend only on the queue size. Longer queues would lead to longer average wait times. The arrival rate $\rho$ however is independent of the queue size. Thus, as $\rho$ increases we would expect the wait times to remain constant.
\section{Task 5}
\label{task5}

The plot of running times of the simulations against $\rho$ is shown in Fig.~\ref{fig8}. We note the following:

\begin{enumerate}
\item At lower values of $\rho$ the simulation take much longer to run that at higher values. 
\item The runtimes decrease exponentially with $\rho$.
\end{enumerate}

\input{task5.tex}

This was to be expected due to the nature of the random number generator. We see the expected values over $10^6$ reruns of the RNG output in Fig.~\ref{fig9}. Note that at $rho=0.05$ the average interarrival times are around 20$\mu s$ and the arrival times decreases exponentially. This must show up in our simulation, and it does.
\newpage
\section*{Task 6: Paxson96 Paper}
\subsubsection*{Anticipatory flow state}

When a network sees traffic from state A to B, it expects (or ``anticipates'') a flow from state B to A. This is called anticipatory flow state. Failure to achieve this state causes routing asymmetry. This can lead to issues such as complicating network measurements, trouble shooting, accounting, and the utility of routers. Also, it increases the likelihood that the network problem apparent in one direction cannot be detected on the other direction.
\subsubsection*{2. Fluttering}
The term fluttering is used to refer to rapidly oscillating routing. Problems with fluttering:
\begin{itemize}
 \item \textit{Unstable Network Paths} 
 \item \textit{Asymmetry}
 \item \textit{Unreliable Estimations}
 \textit{\textit{Spurious ``Fast Retransmission''}} (usually occurs when two routes have different retransmission times.)
\end{itemize}
\subsubsection*{3. Nature of Routing Pathologies}
Table 2 in the paper presents a summary of the routing pathologies. Out of the 5 pathologies presented there, 3 of them: Mid-stream change, Infrastructure failure, and Outage $\ge$ 30 secs, showed worsening trends. Also, none of them improved.

If the author's inferences we considered, it shows that in 1995, the likelihood of a user encountering a serious end-to-end routing problem was 1 to 30 especially for outages that last longer than 30s.

It is difficult to assess the efficacy of the inference. The author states that 1995 (the year under consideration) was an atypical year for internet due to the transition to commercially operated backbones.

\subsubsection*{4. Paper structure}

The paper is organized a sort of survey of 40000 end-to-end internet route measurements to characterize pathological routing conditions, routing stability, and routing symmetry. 

One would expect to see in a paper that deals with measurements some sort of analysis of the difficulties that were pointed out. Especially if the issues were endemic to large packet-switched internetwork, or if there are fixes available.

The authors acknowledge this issue and therefore provide several justifications to why these shortcomings are present in the paper.

\end{document}

